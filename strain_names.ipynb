{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dependencies\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/processed/april_2017.csv', 'data/processed/data_load_clean.json', 'data/processed/jan_2018.csv', 'data/processed/may_2018.csv', 'data/processed/oct_2017.csv', 'data/processed/sept_2018.csv', 'data/processed/strain_name_formal_match.csv']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of paths to our raw data files\n",
    "\n",
    "DATA_DIR = 'data/processed/'\n",
    "\n",
    "### List of files to be read\n",
    "\n",
    "files = os.listdir(DATA_DIR)\n",
    "#print(files)\n",
    "\n",
    "full_file_list = []\n",
    "\n",
    "for file in files:\n",
    "    full_file_list.append(DATA_DIR + file)\n",
    "print(full_file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read The CSVs as dataframes\n",
    "\n",
    "jan_2018 = pd.read_csv('data/processed/jan_2018.csv')\n",
    "april_2017 = pd.read_csv('data/processed/april_2017.csv')\n",
    "may_2018 = pd.read_csv('data/processed/may_2018.csv')\n",
    "oct_2017 = pd.read_csv('data/processed/oct_2017.csv')\n",
    "sept_2018 = pd.read_csv('data/processed/sept_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Timestamp_x', 'plant_id', 'Trimmer', 'grams',\n",
       "       'Simple_Date', 'Unnamed: 5', 'Timestamp_y', 'Name', 'Flower Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may_2018.head()\n",
    "may_2018.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge them into a single DF indexed by timestamp (Timesstamp_x)\n",
    "\n",
    "### Rename all the columns to be the same\n",
    "jan_2018.rename(columns={'Timestamp_x':'time'}, inplace=True)\n",
    "april_2017.rename(columns={'Timestamp':'time'}, inplace=True)\n",
    "sept_2018.rename(columns={'Timestamp_x':'time'}, inplace=True)\n",
    "oct_2017.rename(columns={'Timestamp':'time'}, inplace=True)\n",
    "may_2018.rename(columns={'Timestamp_x':'time'}, inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Merge all the dataframes into a single dataframe\n",
    "\n",
    "df = pd.concat([jan_2018, april_2017, may_2018, oct_2017, sept_2018], axis=0, sort=False)\n",
    "# df.head()\n",
    "# df.columns\n",
    "# df.info()\n",
    "\n",
    "### Clean up \n",
    "# # Dropp uneeded columns\n",
    "# 'Unnamed: 0', 'SImple Date', 'Simple_Date'\n",
    "\n",
    "df.drop(['Unnamed: 0', 'SImple Date', 'Simple_Date', 'Unnamed: 5'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "# df.head()\n",
    "\n",
    "\n",
    "### Look at the strain names\n",
    "\n",
    "df['Name'].value_counts()\n",
    "\n",
    "### Solving match problem\n",
    "## change 'PBB' in the name column to 'Peanut Butter Breath' for better name matching\n",
    "\n",
    "df['Name'] = df['Name'].replace('PBB', 'Peanut Butter Breath')\n",
    "\n",
    "### Export a list of the unique strain names\n",
    "\n",
    "list = df['Name'].unique().tolist()\n",
    "len(list)\n",
    "\n",
    "## sort list in alphabetical order\n",
    "\n",
    "list.sort()\n",
    "list\n",
    "\n",
    "### Export the list to a csv\n",
    "\n",
    "list_df = pd.DataFrame(list)\n",
    "\n",
    "# list_df.to_csv('TEMP/strain_names_raw.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43 entries, 0 to 42\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   name    43 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 472.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "### Clean up and standardize the strain names\n",
    "\n",
    "### Read the of clean strain names\n",
    "\n",
    "clean_names = pd.read_csv('data\\processed\\strain_name_formal_match.csv')\n",
    "\n",
    "clean_names.head()\n",
    "clean_names.info()\n",
    "\n",
    "### Create a list of the clean names\n",
    "\n",
    "clean_list = clean_names['name'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use fuzzywuzzy to match the names\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "### Create a list of the fuzzy matches\n",
    "\n",
    "matches = []\n",
    "\n",
    "for name in list:\n",
    "    match = process.extractOne(name, clean_list)\n",
    "    matches.append(match)\n",
    "\n",
    "### Create a dataframe with the original name, the match name and score in different columns\n",
    "## New frame just with the results\n",
    "matches_df = pd.DataFrame(matches, columns=['match', 'score'])\n",
    "\n",
    "### Merge the matches with the original list\n",
    "matches_df = pd.concat([list_df, matches_df], axis=1)\n",
    "## Rename the first column\n",
    "matches_df.rename(columns={0:'name'}, inplace=True)\n",
    "\n",
    "### Replace the names in the original dataframe with the match names\n",
    "df['Name'] = df['Name'].replace(matches_df['name'].tolist(), matches_df['match'].tolist())\n",
    "\n",
    "#### Clean up the Trimmer names\n",
    "## names to combine\n",
    "Brie = ['Brie', 'Bri']\n",
    "Smitty = ['Smit', 'Smitty']\n",
    "T_Pain = ['TPain', 'T Pain']\n",
    "Gmoney = ['Gmoney', 'Grant']\n",
    "\n",
    "df['Trimmer'] = df['Trimmer'].replace(Brie, 'Brie')\n",
    "df['Trimmer'] = df['Trimmer'].replace(Smitty, 'Smitty')\n",
    "df['Trimmer'] = df['Trimmer'].replace(T_Pain, 'T Pain')\n",
    "df['Trimmer'] = df['Trimmer'].replace(Gmoney, 'Gmoney')\n",
    "\n",
    "# matches_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Working up to here ########## Exports below to single csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['Name'].value_counts()\n",
    "\n",
    "### Export the dataframe to a file to use in tableau\n",
    "\n",
    "df.to_csv('data/processed/viz.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3071ee50c89c1c794c04ecbcb4eb8f9585468a45756c3a74d8e9479e4a2bc436"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
