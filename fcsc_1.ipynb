{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dependencies\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/raw/April_2017.xlsx', 'data/raw/Jan_2018.xlsx', 'data/raw/May_2018.xlsx', 'data/raw/May_2018_2.xlsx', 'data/raw/Oct_2017.xlsx', 'data/raw/plant_codes_Jan_2018.xlsx', 'data/raw/RJ Trim Oct 17 (1).xlsx', 'data/raw/Sept_2018.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of paths to our raw data files\n",
    "\n",
    "DATA_DIR = 'data/raw/'\n",
    "\n",
    "### List of files to be read\n",
    "\n",
    "files = os.listdir(DATA_DIR)\n",
    "#print(files)\n",
    "\n",
    "full_file_list = []\n",
    "\n",
    "for file in files:\n",
    "    full_file_list.append(DATA_DIR + file)\n",
    "print(full_file_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in the data\n",
    "\n",
    "# Creates dataframe from the first sheet of each file in the raw data directory\n",
    "\n",
    "## Returns a list of the dataframes\n",
    "dfs = [pd.read_excel(f) for f in full_file_list if os.path.isfile(f)]\n",
    "\n",
    "\n",
    "\n",
    "### Seperate the list into idividual dataframes\n",
    "\n",
    "\n",
    "may_2017 = dfs[0]\n",
    "jan_2018 = dfs[1]\n",
    "may_2018 = dfs[2]\n",
    "oct_2017 = dfs[4]\n",
    "sept_2018 = dfs[7]\n",
    "plant_id = dfs[5]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp      100\n",
       "Trimmer        100\n",
       "Strain         100\n",
       "Weight (g)     100\n",
       "DATEVALUE      199\n",
       "Simple_Date      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # check the headers of all the dfs\n",
    "jan_2018.head()\n",
    "\n",
    "may_2017.isnull().sum()\n",
    "#may_2017.shape\n",
    "oct_2017.isnull().sum()\n",
    "#oct_2017.shape\n",
    "# plant_id.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### DATA CLEANING ######\n",
    "\n",
    "\n",
    "### REMOVE EMPTY COLUMNS FROM THE DFS\n",
    "\n",
    "may_2018.drop(may_2018.columns[5],axis=1,inplace=True)\n",
    "may_2017.drop(may_2017.columns[3],axis=1,inplace=True)\n",
    "\n",
    "oct_2017.drop(oct_2017.columns[4],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#### DROP ROWS WITH NA VALUES\n",
    "#may_2017.dropna(inplace=True)\n",
    "may_2018.dropna(inplace=True)\n",
    "sept_2018.dropna(inplace=True)\n",
    "jan_2018.dropna(inplace=True)\n",
    "oct_2017.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 4)\n",
      "(85, 5)\n",
      "(92, 5)\n",
      "(166, 5)\n",
      "(121, 5)\n"
     ]
    }
   ],
   "source": [
    "### Check the shape of the dataframes\n",
    "\n",
    "df_list = [may_2017,may_2018,oct_2017,jan_2018,sept_2018]\n",
    "\n",
    "for each in df_list:\n",
    "    print(each.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp      82\n",
      "Strain         82\n",
      "Plant #       145\n",
      "Weight (g)     82\n",
      "dtype: int64\n",
      "Timestamp      0\n",
      "Plant ID       0\n",
      "Trimmer        0\n",
      "Weight (g)     0\n",
      "Simple_Date    0\n",
      "dtype: int64\n",
      "Timestamp      0\n",
      "Trimmer        0\n",
      "Strain         0\n",
      "Weight (g)     0\n",
      "Simple_Date    0\n",
      "dtype: int64\n",
      "Timestamp      0\n",
      "Plant ID       0\n",
      "Trimmer        0\n",
      "Weight (g)     0\n",
      "Simple_Date    0\n",
      "dtype: int64\n",
      "Timestamp      0\n",
      "Plant ID       0\n",
      "Trimmer        0\n",
      "Weight (g)     0\n",
      "SImple Date    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Check the number of rows with NA values\n",
    "\n",
    "\n",
    "for each in df_list:\n",
    "    print(each.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16da5ebd74780a3e742c70b3fe64a587568cb88d914c1ab81d04094053f67c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
